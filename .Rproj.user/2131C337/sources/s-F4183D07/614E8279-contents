---
title: "Project 2"
author: "Amber Horbath"
output:
date: '2020-05-13'
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r}
library(robustbase)
head(CrohnD)
```


## This data set contains the results of 117 patients with Crohn's disease that were given a treatment (placebo, drug 1, or drug 2). The independent variable is the number of adverse events (side effects) while on the given treatment. There are 9 variables: patient ID, the number of adverse events while on treatment drug (nrAdvE), BMI (weight[kg]/height[m]^2), height (cm), the country that the patient lives in (c1 or c2), the sex of the patient, the age of the patient, the patient's weight (kg), and the given treatment for each patient (placebo, drug 1, or drug 2). There are 117 observations in the data set.

```{r}

##ASSUMPTIONS

#density plots for multivariate normality 
library(ggplot2)
ggplot(CrohnD, aes(weight, height)) + geom_point(alpha = .5) +
         geom_density_2d(h=2) + coord_fixed() + facet_wrap(~sex)

##Box's M-test for Homogeneity of Covariance Matrices
library(heplots)
res <- boxM(cbind(weight, height) ~ sex, data=CrohnD)
res

##MANOVA test - to test if height and weight differ between males and females with Crohn's disease
man1<-manova(cbind(weight, height)~sex, data=CrohnD)
summary(man1)

##univariate ANOVAs
summary.aov(man1)

## post-hoc pair-wise t-tests
library(tidyverse)
CrohnD%>%group_by(sex)%>%summarize(mean(BMI),mean(nrAdvE),mean(height),mean(weight))

pairwise.t.test(CrohnD$height,CrohnD$sex, p.adj="none")
pairwise.t.test(CrohnD$weight,CrohnD$sex, p.adj="none")

#ran 1 MANOVA test, 2 univariate ANOVAs, and 2 pair-wise t-tests, 1 box M-test = 6 tests
# alpha = .05/7 = .00833
# probability of at least 1 type-I error: 1-(0.95^6) = 0.265
```
*A one-way MANOVA was conducted to determine the effect of the patients' gender (male or female) on two dependent variables (height and weight of patients). The bivariate density plots for each group showed more of an ovoid shape for the points of both male and female with several outliers in both plots. Therefore, the assumption for multivariate normality was not met. For the homogeneity of covariances assumption I ran Box's M-test which resulted in a p-value of 3.282E-8. Therefore, I can reject the null hypothesis that the observed covariance matrices of the dependent variables (weight and height) are equal across both genders of the patients and the assumption for homogeneity of covariances is met. When I ran the MANOVA, I found that significant differences were found between genders of the patients for at least one of the dependent variables (weight or height) with a p-value of 2.421E-7 (Pillai trace = 0.23453, F-statistic = 17.463, p<0.0001). Univariate ANOVAs for each dependent variable were conducted using the Bonferroni method to control the Type I error rate. Only the univariate ANOVA for height was significant with an alpha of 0.0001 (p-value = 5.829E-8, F-statistic = 33.687). The univariate ANOVA for weight was not significant with alpha=0.0001 (p-value = 0.001, F-statistic = 11.392). However, with the bonferroni adjusted alpha of 0.00833 both variables were significant. Post-hoc analysis was performed conducting pairwise t-tests to determine which gender differed in patient weight and height. Both sexes were found to differ significantly from each other in terms of patient height and weight after adjusting for multiple comparisons (bonferroni alpha = 0.05/6 = 0.00833). There were 6 tests performed (1 MANOVA, 2 univariate ANOVAs, 2 pair-wise t-tests, and 1 box M-test) and the probability of at least one Type I error is 1-(0.95^6) = 0.265.*

```{r}
##randomization test

##to get F-statistic
summary(aov(nrAdvE~country,data=CrohnD))

obs_F<-2.941
Fs<-replicate(5000,{ 
new<-CrohnD%>%mutate(nrAdvE=sample(nrAdvE)) 

SSW<- new%>%group_by(country)%>%summarize(SSW=sum((nrAdvE-mean(nrAdvE))^2))%>%
summarize(sum(SSW))%>%pull
SSB<- new%>%mutate(mean=mean(nrAdvE))%>%group_by(country)%>%mutate(groupmean=mean(nrAdvE))%>%
summarize(SSB=sum((mean-groupmean)^2))%>%summarize(sum(SSB))%>%pull
(SSB/1)/(SSW/115) #F-statistic = 41.281
})

hist(Fs, prob=T); abline(v = obs_F, col="red",add=T)
mean(Fs>obs_F) #p-value is 0.0876
```
*H0 = There is no significant mean difference between the groups.*
*HA = There is a significant mean difference between the groups.*
*After performing the randomization test, we get a p-value of 0.0876 (p-value < alpha(0.05) ) which means that we fail to reject the null-hypothesis and can conclude that there is no signifcant mean difference between the groups (number of adverse events and the country that the patient resides in). Not all of the 5000 F-statistics generated under the null hypothesis were bigger than our actual F statistic (2.941).*

```{r}
library(sandwich);library(lmtest)
fit<-lm(nrAdvE ~ age*weight, data=CrohnD) #Regression before centering
summary(fit)

CrohnD$weight_c <- CrohnD$weight - mean(CrohnD$weight)
CrohnD$age_c <- CrohnD$age - mean(CrohnD$age)
fit_c<-lm(nrAdvE ~ age_c*weight_c, data=CrohnD)
summary(fit_c)


new1<-CrohnD
new1$weight_c<-mean(CrohnD$weight_c)
new1$mean<-predict(fit_c,new1)
new1$weight_c<-mean(CrohnD$weight_c)+sd(CrohnD$weight_c)
new1$plus.sd<-predict(fit_c,new1)
new1$weight_c<-mean(CrohnD$weight_c)-sd(CrohnD$weight_c)
new1$minus.sd<-predict(fit_c,new1)
newint<-new1%>%select(nrAdvE,age_c,mean,plus.sd,minus.sd)%>%gather(weight_c,value,-nrAdvE,-age_c)

mycols<-c("#619CFF","#F8766D","#00BA38")
names(mycols)<-c("-1 sd","mean","+1 sd")
mycols=as.factor(mycols)


##Interaction Plot
ggplot(CrohnD,aes(age_c,nrAdvE),group=mycols)+geom_point()+geom_line(data=new1,aes(y=mean,color="mean"))+geom_line(data=new1,aes(y=plus.sd,color="+1 sd"))+geom_line(data=new1,aes(y=minus.sd,color="-1 sd"))+scale_color_manual(values=mycols)+labs(color="weight (cont)")+theme(legend.position=c(.9,.2))

##ASSUMPTIONS
##Linearity/Homoskedasticity
resids <- fit_c$residuals
fitvals<-fit_c$fitted.values
ggplot()+geom_point(aes(fitvals,resids))+geom_hline(yintercept=0, color='green')

##Normality
ks.test(resids, "pnorm", mean=0, sd(resids)) ## H0: true distribution is normal, p-value = 0.0003672

##regression with robust standard errors
summary(fit_c)$coef[,1:2] #uncorrected SEs
coeftest(fit_c, vcov = vcovHC(fit_c))[,1:2] #corrected SEs

```
*Interpretations of coeffiecients - Intercept: The predicted number of adverse events for an average weight and age of a patient is 2.02952. Age: Patients show an increase of 0.040413 adverse events for every 1 year increase in age, on average. Weight: Patients show an increase of 0.007811 adverse events for every one kg increase in weight, on average. Age:Weight interaction: The difference in slope for the number of adverse events is 0.002889 for age and weight of the patients. The assumptions for linearity and homoskedasticity were checked by plotting the residuals of the model. The plot of the residuals looks very 'iffy.' On one hand, the points at the top of the plot show a pretty even spread with no real pattern, but towards the bottom of the plot, there is an obvious trend occurring. Therefore, the assumptions for linearity and homoskedasticity are not met. When checking the normality assumption, I ran the one-sample Kolmogorov-Smirnov test which resulted in a p-value of 0.0003672. The null hypothesis for the test is that the true distribution is normal and since we have a p-value that is less than 0.05, we reject the null and the normality assumption is not met. After recomputing the regression with robust standard errors, the new resulting standard errors are greater and this is because it is accounting for the penalty for not meeting the homoskedasticity assumption. Because the R^2 value is 0.02805, we can say that 2.805% of the variation is explained by the model.*
```{r}
##Bootstrapped SEs

samp_distn<-replicate(5000, {
boot_dat<-boot_dat<-CrohnD[sample(nrow(CrohnD),replace=TRUE),]
fit2<-lm(nrAdvE ~ age_c * weight_c, data=boot_dat)
coef(fit2)
})

## Estimated SEs
samp_distn%>%t%>%as.data.frame%>%summarize_all(sd)
###COMPARE
```
*Comparing the standard errors from the original model, the bootstrapped standard errors, and the robust standard errors, the original model had the smallest standard errors, the robust standard errors were the greatest, and the bootstrapped standard errors were in between.*
```{r}
library(glmnet)

class_diag<-function(probs,truth){
if(is.numeric(truth)==FALSE & is.logical(truth)==FALSE) truth<-as.numeric(truth)-1
tab<-table(factor(probs>.5,levels=c("FALSE","TRUE")),truth)
prediction<-ifelse(probs>.5,1,0)
acc=mean(truth==prediction)
sens=mean(prediction[truth==1]==1)
spec=mean(prediction[truth==0]==0)
ppv=mean(truth[prediction==1]==1)
#CALCULATE EXACT AUC
ord<-order(probs, decreasing=TRUE)
probs <- probs[ord]; truth <- truth[ord]
TPR=cumsum(truth)/max(1,sum(truth))
FPR=cumsum(!truth)/max(1,sum(!truth))
dup<-c(probs[-1]>=probs[-length(probs)], FALSE)
TPR<-c(0,TPR[!dup],1); FPR<-c(0,FPR[!dup],1)
n <- length(TPR)
auc<- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )
data.frame(acc,sens,spec,ppv,auc)
}


#Logistic regression
log_fit <- glm(country ~ age + treat, data = CrohnD, family = "binomial")
summary(log_fit)

exp(coef(log_fit))

prob<-predict(log_fit,type="response")
pred<-ifelse(prob>.5,1,0)
table(prediction=pred, truth=CrohnD$country)%>%addmargins

(76+2)/117 #accuracy
2/39 #sensitivity (TPR)
76/78 #specificity (TNR)
2/4 #precision (PPV)

CrohnD$logit<-predict(log_fit,type="link") #log-odds

## Density plot of log-odds for both countries:

CrohnD%>%ggplot()+geom_density(aes(logit,color=country,fill=country), alpha=.4)+
  theme(legend.position=c(.85,.85))+geom_vline(xintercept=0)+xlab("logit (log-odds)")+
  geom_rug(aes(logit,color=country))+
  geom_text(x=-5,y=.07,label="TN = 431")+
  geom_text(x=-1.75,y=.008,label="FN = 19")+
  geom_text(x=1,y=.006,label="FP = 13")+
  geom_text(x=5,y=.04,label="TP = 220")

##ROC plot
library(plotROC)
ROCplot<-ggplot(CrohnD)+geom_roc(aes(d=country,m=prob), n.cuts=0) 
ROCplot
calc_auc(ROCplot) #AUC = 0.6382314

#10-fold CV
set.seed(1234)
k=10 

data<-CrohnD[sample(nrow(CrohnD)),] 
folds<-cut(seq(1:nrow(CrohnD)),breaks=k,labels=F) 

diags<-NULL
for(i in 1:k){

  train<-data[folds!=i,] 
  test<-data[folds==i,]
  
  truth<-test$country
  
  
  fit3<-glm(country~age+treat,data=train,family="binomial")
  
 
  probs<-predict(fit3,newdata = test,type="response")
  
  
  diags<-rbind(diags,class_diag(probs,truth))
}


summarize_all(diags,mean)
```
*Interpretation of coefficients - Intercept: The odds of being from country 2 and under the placebo treatment, age = 0 is -3.23246. Age: Controlling for treatment type, for every 1 year increase in the patient's age, the odds of being from country 2 increases by a factor of 0.04396. Treatment 1: Controlling for age, odds of being from country 2 and under treatment 1 is 0.10717 times greater than the odds of being from country 2 when under the placebo treatment. Treatment 2: Controlling for age, the odds of being from country 2 and under treatment 2 is 0.19283 times greater than the odds of being from country 2 and under the placebo treatment. The accuracy of this model is 0.667 which means that only 66.7% of the patients are being correctly predicted in terms of what country they live in. The sensitivity or the true positive rate is 0.0512 which means that there is a 5.12% chance of predicting that the patient is from country 2 when that is actually where they are from. The specificity or the true negative rate is 0.9744 which means that there is a 97.44% chance of predicting that a patient is from country 2 when they are actually from country 1. The precision is 0.5 which means that only 50% of the patients who live in country 2 are being classified as such. The AUC which summarizes both the specificity and the sensitivity of the logistic regression calculated from the ROC plot is 0.6382314 which is categorized as poor. After the 10-fold cross validation, the out-of-sample accuracy is now 0.6576, the sensitivity increased to 0.0533, and the specificity decreased to 0.955 with an even worse AUC of 0.5246.*
```{r}
##LASSO regression
y <- as.matrix(CrohnD$sex)
x <- model.matrix(sex~ -1+., data=CrohnD)
head(x)

set.seed(1234)
cv<-cv.glmnet(x,y,family='binomial')
lasso<-glmnet(x,y,family='binomial',lambda=cv$lambda.1se)
coef(lasso)

#cross-validating lasso model
set.seed(1234)
k=10 
data1<-CrohnD[sample(nrow(CrohnD)),] 
folds<-cut(seq(1:nrow(CrohnD)),breaks=k,labels=F) 
diags<-NULL
for(i in 1:k){

train<-data1[folds!=i,]
test<-data1[folds==i,]
truth<-test$sex

fit_l<-glm(sex~.,data=train,family="binomial")
probs<-predict(fit_l,newdata = test,type="response")

diags<-rbind(diags,class_diag(probs,truth))
}
diags%>%summarize_all(mean)
```
*Lasso regression - sex of patients tested against all other predictors. The only variable that was retained after performing the lasso regression is height. Therefore, height is the most predictive variable of the patients' sex (makes sense!). A 10-fold cross validation was performed on the model and the AUC is 0.8247 (in the "Good" range) which is much better than the AUC from the previous 10-fold cross validation.*